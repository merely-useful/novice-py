# Python data manipulation {#py-data-manipulation}

```{r py-data-manipulation-setup, include=FALSE}
source(here::here("_common.R"))
knitr::opts_chunk$set(eval = FALSE)
```

With just a few Python libraries and commands, you can rearrange, process, manipulate, and
analyze tabular data easily and reproducibly.

This material is based on a [workshop run by UofT Coders](https://github.com/UofTCoders/workshops-dc-python)
and a [Data Carpentry Python workshop](https://datacarpentry.org/python-ecology-lesson/).

## How can I read tabular data into a program? {#py-data-manipulation-reading}

The package `pandas` is built for working with tabular data, and the `pandas`
function `read_csv()` takes a tabular text file as input and returns a `pandas`
data frame.

```{python, eval=FALSE}
# reading in tabular data - example
import pandas as pd # import the pandas package

# where is the file located on your computer?
# you can use a path relative to the current directory (shown in the example),
# or the full path (i.e. /home/madeleine/data/file.csv)
filename = "data/nyc-dog-licenses.csv"

# the function pd.read_csv() takes a file path as its default input and tries to
# read in a table of data.
# here we assign the function's output to a variable called "dog_licenses"
dog_licenses = pd.read_csv(filename)
```

```{python, echo=FALSE}
# To import the .gz dataset.
import pandas as pd 
filename = "data/nyc-dog-licenses.csv.gz"
dog_licenses = pd.read_csv(filename)
```

You can also pass a url as the `filename` argument in `read_csv()`:

```{python, eval=FALSE}
data_link = 'https://github.com/merely-useful/merely-useful.github.io/raw/book/data/nyc-dog-licenses.csv.gz'
dog_licenses = pd.read_csv(data_link)
```

The `read_csv()` function assumes by default that the column delimiter
in the file is a comma and that the first line of the file contains column names.
To specify a different delimiter (for example tab), pass the argument `sep=\t`.
If the data has no column names, pass the argument `header=None`, or give a list
of column names using the argument `names=['column1', 'column2']`.

Data can come in many formats, and `read_csv()` has many options to reflect this.
The `read_csv()` [help page](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)
describes all the possible arguments that can be used to tell `read_csv()` about
how your data is organized.

Here's what the first few rows and columns of the dog license data look like if
you open the file in a spreadsheet program:

FIXME: This image needs to be added. It doesn't exist.
<!-- ![dog license data in a spreadsheet program](./figures/py-data-manipulation/NYC-dog-licenses-snapshot.png) -->

The structure of the data is exactly the same after reading it with `read_csv()`.
You can get a quick view of the data using the method `.head()`:

```{python}
dog_licenses.head()
```

## How can I select subsets of my data?

This data frame has rows and columns (it has 2 dimensions). To extract specific
data from it (also referred to as "subsetting"), columns and/or rows can be selected either by their name or location.

### Selecting columns

To select a column, pass the column name as a string to the data frame, using square brackets to indicate that we want to select from the data frame (similar to subsetting lists).

```{python}
# to see what column names there are, we can use the method .columns
dog_licenses.columns

# to get a single column, use square brackets and the column name in quotation marks. This is case sensitive!
dog_licenses["animal_name"].head()

# to get multiple columns, provide a list of column names inside the square brackets.
dog_licenses[["animal_name", "animal_gender"]].head()
```

Notice that if you provide a list, the returned object is a data frame of one or more columns, but if
you provide a single item not in a list, it's a `Series` object with a one column. There are situations where it is beneficial to work with one over the other, but for now it is enough to know the differences when selecting columns.

### Selecting rows

Selecting with single brackets (`[]`) is a shortcut to common operations such
as selecting columns by labels as above. If you instead pass a range of numbers (e.g. `[0:10]`), the corresponding *row numbers* will be selected.

```{python}
dog_licenses[0:10]
```

### Selecting rows and columns

The function `.loc[]` gives more flexible control over both rows and columns by label. The syntax is `loc[<rows>, <columns>]`.

For example, you can select the first 10 rows and a slice of columns:

```{python}
dog_licenses.loc[0:10, "animal_name":"breed_name"]
```

You can use logical operations to filter your data based on some criteria.

```{python}
# get rows where 'animal_gender' is female
dog_licenses[dog_licenses['animal_gender'] == 'F'].head()

# you can also get specific columns with .loc:
dog_licenses.loc[dog_licenses['animal_gender'] == 'F', ['animal_name', 'animal_gender']].head()
```

A single expression can also be used to filter for several criteria, either
matching all criteria (`&`) or any criteria (`|`). These special operators are
used instead of `and` and `or` to make sure that the comparison occurs for each
row in the data frame. Parentheses are added to indicate the priority of the
comparisons.


```{python}
# the symbol '&' can be used to combine multiple logical comparisons
# '==' means 'is equal to'
dog_licenses.loc[(dog_licenses['animal_gender'] == 'F')
           & (dog_licenses['breed_name'] == 'Boxer')
           & (dog_licenses['animal_name'] == 'MILEY'), 'animal_name' : 'breed_name']

# OR (|)
# the order of comparisons can be structured with parentheses. Here we want the OR comparison
# to happen before the AND comparison.

dog_licenses.loc[(dog_licenses['animal_name'] == 'MILEY') & ((dog_licenses['breed_name'] == 'Boxer')
         | (dog_licenses['breed_name'] == 'Labrador Retriever')),  'animal_name' : 'breed_name']
```

## How can I calculate new values?

A new column can be added to a data frame by
assigning values to a new column label. The assigned values should be either the same length as the
original data frame, or a single value.

```{python}
# create a new column and fill all rows with the value 'test'
dog_licenses['new_column'] = 'test'
dog_licenses.head()

# drop the column we just made
dog_licenses = dog_licenses.drop(columns='new_column')
```

We can also create new columns by doing operations on existing columns.
For example, let's create a column with the length of the dog's name.

```{python}
# create a new column called 'name_length'
# the accessor `.str` gives access to string methods that can be applied to the column values, e.g. `len()`
dog_licenses['name_length'] = dog_licenses['animal_name'].str.len()

# we can see that the new column has been added to the end of the data frame
dog_licenses.columns
```

Let's create a column with the age of each animal at the time it was licensed.
Note: this step takes a few seconds to run.

To calculate the age of each animal at licensing, we'll use the animal birth date
and the date it was licensed. `pandas` has a data type called `datetime` that
allows it to deal with dates: subtracting two dates, for instance, is different
than subtracting two numbers. The function `to_datetime()` converts a string
into a `datetime` object.

```{python}
# use to_datetime to create a datetime object for each date we're using
animal_birth_date = pd.to_datetime(dog_licenses['animal_birth_date'])
license_issued_datetime = pd.to_datetime(dog_licenses['license_issued_date'])

# subtract the birth date from the license date
age_when_licensed = license_issued_datetime - animal_birth_date

# assign age_when_licensed to a new column
dog_licenses['age_when_licensed'] = age_when_licensed
```

## How can I tell what's gone wrong in my programs?

Typos and errors are inevitable - they happen to everyone. Python provides
error messages if it can't run your code that will help you figure out where
the problem is. Generally, there are two types of errors: syntax errors - where Python can't execute the code, e.g. due to a missing parenthesis; and runtime erros - where Python executed the code but ran into an illegal operation, e.g. an undefined variable name was used in an operation.

```{python, error = TRUE}
# this code generates a syntax error
dog_licenses['animal_name'
```

The very bottom of the error message is the most helpul place to start looking:
this says what kind of error it is (e.g. `SyntaxError`, `ValueError`,
`TypeError`, etc) and sometimes includes a message that describes what went
wrong.

The caret (`^`, similar to an up-arrow) points to the place where the error happened: in this case, there's a
missing square bracket, so the error we got was that Python reached the end of
the file before it expected to because we didn't include proper punctuation.

```{python, error = TRUE}
# this code generates a TypeError error (there's nothing wrong with the syntax,
# but Python can't execute it because of a different error)

dog_licenses['animal_name'] < dog_licenses['zip_code']
```

The last line again tells us what went wrong, but this time we get a
*traceback*: Python is showing us the series of steps that it followed
internally before it hit an error. This is helpful because often the error will
ultimately occur inside a function we're using but whose code we haven't ever
seen, so Python shows us both what specifically went wrong inside the function,
but also what line of our code caused the original cascade. Here, the offending
line is pointed to at the very top of the traceback, and by reading the error
message at the bottom we can see that the problem was that we can't use the
'less than' `<` comparison between two objects when one is a string
(`dog_licenses['animal_name']`) and the other is an integer (`dog_licenses['zip_code']`).

## How can I summarize and group my data?

Many data analysis tasks can be approached using the *split-apply-combine
paradigm*: split the data into groups, apply some analysis to each group, and
then combine the results.

`pandas` facilitates this workflow through the use of `groupby()` to split
data and summary/aggregation functions such as `mean()` which collapses each
group into a single-row summary of that group. The arguments to `groupby()` are
the column names that contain the categorical variables by which summary
statistics should be calculated.

Let's start with a smaller data frame of the top 10 most common dog breeds and
with only boroughs that are listed 5 or more times.

```{python}
# get a list of the 10 most common breed names
# the attribute 'index' gives us just the row descriptions and not the values
common_breeds = dog_licenses['breed_name'].value_counts()[:10].index

# create a new data frame with only the common breeds
dog_licenses_common_breeds = dog_licenses[dog_licenses['breed_name'].isin(common_breeds)]
```

`groupby()` enables us to break the data down into groups and perform operations
on each group. To look at how many animals of each sex there are in each of the
most common breeds, we can use `groupby()`:

```{python}
dog_licenses_common_breeds.groupby('breed_name')['animal_gender'].value_counts()
```

For some breeds, male dogs are much more common, but for other dogs the ratio
is about equal.

Other summary statistics, such as the mean, minimum, and maximum can be calculated:

```{python}
dog_licenses_common_breeds.groupby(['borough'])['name_length'].mean()
```

Groups can also be created from multiple columns. For example, we can group by
both breed and borough and look for the maximum name length:

```{python}
dog_licenses_common_breeds.groupby(['borough', 'breed_name'])['name_length'].max()

# add a sort to show the longest name first
dog_licenses_common_breeds.groupby(['borough', 'breed_name'])['name_length'].max().sort_values(ascending=False)
```

A Yorkshire Terrier from Manhattan holds the longest name in the dataset.

Instead of choosing a single summary statistic to calculate each time, the more
general `agg()` method can be called to aggregate or summarize by *any*
existing aggregation functions. This approach is more flexible and powerful
since multiple aggregation functions can be applied in the same line of code by
passing them as a list to `agg()`.

```{python}
dog_licenses_common_breeds.groupby(['breed_name'])['name_length'].agg(['count','min', 'max', 'mean'])
```

Yorkshire Terriers also have the largest mean name length of the top 10 breeds.

## How can I save my results?

We can use the `to_csv()` command to do export a data frame in CSV format. Note
that the code below will by default save the data into the current working
directory. We can save it to a different folder by adding the foldername and a
slash to the filename. We use the 'index=False' so that pandas doesn't include
the index number for each line.

```{python}
# Write data frame to CSV
dog_licenses_common_breeds.to_csv('dog_licenses_common.csv', index=False)
```

## How can I tidy up my data?

Even carefully created and curated data can present difficulties at the analysis step.
Here are a few tidying steps you might consider when exploring a new data set.

### Modifying column names

In this book we are using *snake case* for column names (`snake_case`,
see the [style guide](https://github.com/merely-useful/merely-useful.github.io/blob/c1bef59634070573922f30dd933acc20cb3ff300/style.Rmd)
for more information about coding format and style), but another common format
is called *camel case* (`CamelCase`). The following code uses the package `inflection`
to convert a list of column names from snake case to camel case.

```{python}
# import the underscore function which creates camel case
from inflection import underscore
from inflection import camelize

# here's what the columns look like in snake case
dog_licenses.columns
```

```{python}
# get a list of columns in camel case for the data frame 
camel_case_columns = [camelize(column) for column in dog_licenses.columns]

# reassign the columns 
dog_licenses.columns = camel_case_columns

# here's what the columns now look like in camel case
dog_licenses.columns

# here is to revert to snake case
snake_case_columns = [underscore(column) for column in dog_licenses.columns]

dog_licenses.columns = snake_case_columns
```

If the column names have any whitespace in them, the following one-liner will
rename them without the whitespace.

```{python}
# Remove whitespace from column names
dog_licenses = dog_licenses.rename(columns=lambda x: x.strip())
```

You might also decide that you don't want to keep some columns; you can drop them
from the data frame using the method `drop()`. For example, the following code drops the columns
`city_council_district` and `census_tract_2010` from the `dog_licenses` data frame.

```{python}
# drop two columns
dog_licenses = dog_licenses.drop(columns=["city_council_district", "census_tract_2010"])
```

### Cleaning values

Often, data entered by humans can have errors or inconsistent formats. The values
in the `borough` column of the dog license data are a good example. To see all the
unique values in this column, we can use the pandas method `unique()`.

```{python}
# list all boroughs
dog_licenses['borough'].unique()
```

Instead of the names of the unique boroughs, the number of boroughs can be
returned with the nunique() method.

```{python}
# list all boroughs
dog_licenses['borough'].nunique()
```

The number of dog registrations for each borough can be computed with the
`value_counts()` method.

```{python}
# list and count all the values of 'borough'
dog_licenses['borough'].value_counts()
```

There are at least three different variations of `New York` with various capitalizations.
`New York`, `NEW YORK`, and `new york` should probably all be considered the same
borough, but unless we do something to these names, `pandas` will consider them unique.

A good first pass to clean this up is to apply some string methods to this column.
The method `str` allows us to use any Python function that works on strings and
apply it to a data frame.

We can convert all the boroughs to lower case to combine all the names with
the same spelling but different capitalizations.

```{python}
dog_licenses['borough'] = dog_licenses['borough'].str.lower()
```

This reduces the number of unique boroughs. Not bad, but another look
at `dog_licenses['borough'].value_counts()` shows us that we still have some issues:
'staten island' and 'staten is' are two different values that probably refer to the
same borough. At this point automatic processing might give way to some human
oversight: for instance, we could look up the true names of New York's boroughs
and see that there are only five. We could then cross-reference the 'borough' column
with other location information like the zip code or city council district to assign
correct boroughs to some of the mis-named ones. We could also do a few things
manually, such as renaming 'staten is'
to 'staten island', which would take care of 267 mis-labeled entries.

```{python}
# replace values in the 'borough' column
dog_licenses['borough'] = dog_licenses['borough'].replace('staten is', 'staten island')
```

We could also decide that it's not worth it to meticulously fix the stragglers and
drop any rows whose borough appears less than, say, five times in the dataset.

```{python}
# get a list of the unique borough names
borough_names = dog_licenses['borough'].unique()

# since the value_counts sorts the borough names, let's first store the sorted borough names
sorted_borough_names = dog_licenses['borough'].value_counts().index.values

# get a list of all the borough names that have 5 or more members:
large_borough_names = sorted_borough_names[dog_licenses['borough'].value_counts() >= 5]

# the method `isin(list)` returns True or False for each row if the value is in `list`
dog_licenses_large_boroughs = dog_licenses[dog_licenses['borough'].isin(large_borough_names)]

# look at the unique boroughs after this operation
dog_licenses_large_boroughs['borough'].value_counts()
```

## Summary {#py-data-manipulation-summary}


## Exercises {#py-data-manipulation-exercises}

1. **Understanding data frame structure**

Based on the output of `dog_licenses.info()`, can you answer the following questions?

 - What is the class of the object `dog_licenses` (where
   `dog_licenses = pd.read_csv("data/nyc-dog-licenses.csv")`)?
 - How many rows and how many columns are in this object?
 - Why is there not the same number of rows (observations) for each column?

2. **Finding messy values**

- Get a list of the unique values in the `breed_name` column of the dog license
data using `value_counts()` or `unique()`. Sort this list alphabetically. (Hint:
use the `sort_values()` function.) Look at the first 50 values. Do you see any
breed names that should be combined?

2. **Subsetting data by row**

- Extract the 200th and 201st row of the dog license dataset and assign the
resulting data frame to a new variable name (i.e. `data_200_201`). Remember
that Python indexing starts at 0!

- With the data frame `dog_licenses = pd.read_csv("data/nyc-dog-licenses.csv")`:
    - How can you get the same result as from `dog_licenses.head()` by using row slices
    instead of the `head()` method?

- There are at least three distinct ways to extract the last row of a data
frame. How many can you come up with?

3. **Selecting and filtering data**

- Subset the dog license data frame `data` to include only female dogs and retain
only the columns 'animal_name', 'animal_gender' and 'breed_name'. There are
multiple ways this could be done.

- How many dog licenses belong to dogs named "Queen" that live in "Queens"?

3. **Error messages**

Run the following code. What type of error does it generate?

```{python}
dog_licenses.loc[0:10, 'animal_name', 'breed_name']
```

Edit the code to prevent it from causing an error.

4. **Creating new columns**

  1. Add two new columns to the `dog_licenses` data frame: one that contains the length of the
  breed name from the `breed_name` column, and one that contains just the first
  letter of the `animal_name` column.

  2. Create a new data frame from the dog license data frame `dog_licenses` that contains only the `animal_birth_date`, `animal_name`, and `breed_name` columns.
  Add two new columns to this new data frame: one called `birth_year` which contains just the year from the `animal_birth_date` column, and one
  called `birth_month` which contains just the month from the `animal_birth_date` column.


5. **groupby()**

  1. Use `groupby()` and `agg()` with the dog license data frame `dog_licenses` after adding the `age_when_licensed` column to find the mean, min, and max age when a dog was licensed in days grouped by `borough`. Hint: the pandas `timedelta` format of the `age_when_licensed` column will make calculating numeric quantities difficult; try creating a new column for the licensed age in days using `dog_licenses['age_when_licensed'].dt.days`.

  Which borough has the largest mean time until licensing? Return the columns `breed_name`, `borough`, and `age_when_licensed`. Hint: Look into the `idxmax()` method.

  2. How many dogs are female and how many are male?


## Key Points {#py-data-manipulation-keypoints}

```{r, child="keypoints/py-data-manipulation.md"}
```

```{r, include=FALSE}
knitr::opts_chunk$set(eval = TRUE)
```

